---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 1 with R (STAT 301-2)
author: "Miracle Ramos"
pagetitle: "PM1 Miracle Ramos"
date: today

format:
  html:
    toc: true
    toc-depth: 4
    toc-location: left
    embed-resources: true
    link-external-newwindow: true

execute:
  warning: false

from: markdown+emoji
reference-location: margin
citation-location: margin
---



::: {.callout-tip icon=false}

## Github Repo Link

[Miracle's GitHub Repo Link (miracleramos2025)](https://github.com/stat301-2-2025-winter/final-project-2-miracleramos2025.git)

:::

## Introduction

#### Research Objective
The goal of this project is to develop a predictive model that forecasts Airbnb rental prices in New York City. Specifically, I will predict the price of an Airbnb listing based on various features such as location, property type, number of reviews, availability, and host details.

#### Prediction Type
This is a regression problem, where the target variable will be the `price` of an Airbnb listing. The model will be trained using supervised learning techniques.

#### Motivation
As Airbnb continues to be a dominant platform in the short-term rental market, understanding pricing trends is crucial for both hosts and guests. This project allows me to explore machine learning techniques while analyzing factors that contribute to Airbnb pricing in NYC. By predicting prices accurately, I aim to provide insights into market trends and pricing strategies.

## Data Overview

#### Primary Dataset
The dataset used for this project is sourced from [Kaggle: New York City Airbnb Open Data](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv). It contains details about **Airbnb listings in NYC from 2019**, including **host details, property characteristics, location, reviews, and pricing.**

#### Datasets Used

  1. `AB_NYC_2019.csv` â€“ Includes host information, listing details, location, and pricing metrics.

**Description:** 
This dataset provides a comprehensive view of Airbnb activity in NYC, making it suitable for building a model that predicts listing prices based on various factors.

**Citations:** <br>

  - Kaggle: Dgomonov, [New York City Airbnb Open Data](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)


#### Data Quality Check

```{r}
#| label: tbl-data-quality-check
#| tbl-cap: "Data Quality Check"
#| echo: false

# load packages
library(knitr)

# load saved data summary table
load("data/dataset_summary.rda")
load("data/var_type_summary.rda")

# display
kable(dataset_summary, caption = "Data Quality Summary")
kable(var_type_summary, caption = "Variable Type Summary")

```


#### Variable Types

  - **Categorical Variables:** There are 5 categorical variables, `name`, `host_name`, `neighborhood_group`, `neighborhood`, and `room_type` in the New York City Airbnb Open Data dataset.
  - **Date Variables:** `last_review` is the only date variable in the New York City Airbnb Open Data dataset.
  - **Numerical Variables:** There are 10 numerical variables, `id`, `host_id`, `latitude`, `longitude`, `price`, `minimum_nights`, `number_of_reviews`, `reviews_per_month`, `calculated_host_listings_count`, and `availability_365` in the New York City Airbnb Open Data dataset.

#### Missingness

  - The dataset has an overall missingness percentage of **2.57%**.
  - The `reviews_per_month` column has **10,052** missing values, which corresponds to listings with no reviews.
  - The `last_review` column also has **10,052** missing values, indicating that these listings have never received a review.
  - No missing values were found in critical numeric columns like `price`, `minimum_nights`, and `availability_365`.

#### Data Tidying 

  - Fill missing values in `reviews_per_month` with 0 where no reviews exist.
  - Convert `last_review` to a standardized date format.
  - Encode categorical variables like `neighbourhood_group` and `room_type` for modeling.


## Target variable analysis
#### Target Variable
The primary target variable for this analysis is `price`, a numerical variable representing the nightly cost of an Airbnb listing. Understanding price variations is important for both hosts and guests because it reflects market trends, demand, and listing characteristics. Predicting price based on key features such as location, property type, and availability will help identify factors that influence Airbnb rental pricing in New York City.

#### Univariate Analysis
```{r}
#| label: tbl-price-summary
#| tbl-cap: "Price Summary"
#| echo: false

# Load required packages
library(ggplot2)
library(dplyr)
library(knitr)
library(readr)

# Load dataset
airbnb_data <- read_csv("data/AB_NYC_2019.csv")

# Summarize price data
price_summary <- airbnb_data %>% summarize(
  mean_price = mean(price, na.rm = TRUE),
  median_price = median(price, na.rm = TRUE),
  max_price = max(price, na.rm = TRUE),
  min_price = min(price, na.rm = TRUE),
  std_dev = sd(price, na.rm = TRUE)
)

# Display summary table
kable(price_summary)
```
The **average Airbnb price in NYC is $152.72** but the median is $106, this shows that a few expensive listings raise the average. Prices range from $0 (possibly promotions or errors) to $10,000, with a high standard deviation of $240.15. This indicates large price differences across listings.
  
#### Symmetry & Skewness
```{r}
#| label: fig-price-dist
#| fig-cap: "Distribution of Airbnb Prices"
#| echo: false

# Plot price distribution
ggplot(airbnb_data, aes(x = price)) +
  geom_density(fill = "slateblue1", alpha = 0.5) +
  xlim(0, 1000) + 
  labs(title = "Density Plot of Airbnb Prices in NYC", x = "Price ($)", y = "Density")

```

The distribution is highly **right-skewed**, with a small number of extremely high priced listings. Most listings fall under $500 per night but outliers significantly increase the maximum price.




#### Missingness
```{r}
#| label: tbl-price-missing
#| tbl-cap: "Missing Values in Price"
#| echo: false

missing_price <- sum(is.na(airbnb_data$price))
kable(data.frame(Variable = "Price", Missing_Values = missing_price))
```

There are **no missing values** in the `price` variable, all listings have a recorded price. Since the target variable is complete, this will allow for more accurate modeling and analysis.


#### Transformations Considered

```{r}
#| label: fig-log-price-dist
#| fig-cap: "Log10 Transforation on Distribution of Prices"
#| echo: false

# apply log10 transformation
airbnb_data <- airbnb_data |>
  mutate(log_price = log10(price + 1))

# Plot transformed price distribution
ggplot(airbnb_data, aes(x = log_price)) +
  geom_density(fill = "skyblue1", alpha = 0.5) +
  labs(title = "Log10 Transformation Density of Airbnb Prices", x = "Log10(Price + 1)", y = "Density")

```

The **log10 transformation** of Airbnb prices **helps reduce skewness** and creates a more normalized distribution, making it easier for regression models to capture patterns in the data. The transformed distribution is more symmetric and indicates that extreme price outliers have less influence on the model.


## Analysis Plan

#### Model Types
To predict Airbnb listing prices in NYC, I will use six models:

- **Baseline Model**: Predicts the mean price as a simple benchmark.
- **Linear Model**: Establishes a basic regression baseline.
- **Elastic Net Regression**: Balances lasso and ridge penalties for variable selection.
- **Lasso Regression**: Selects the most important predictors by applying strong penalties.
- **Random Forest**: Captures complex relationships with an ensemble of decision trees.
- **Boosted Trees**: Further refines tree-based predictions using boosting techniques.


#### Preprocessing and Resampling
- **Data Splitting**: 80% training, 20% testing.
- **Resampling Method**: 10-fold cross-validation to assess model performance.
- **Feature Engineering**:
  - **Recipe 1 (Basic)** (`2_recipe1_basic.R`): Standardizes numerical variables and applies one-hot encoding for categorical variables.
  - **Recipe 1 (Advanced)** (`2_recipe1_advanced.R`): Builds on the basic version by adding feature interactions and polynomial terms while removing redundant predictors.
  - **Recipe 2 (Basic)** (`3_recipe2_basic.R`): Uses a different transformation approach suited for models that require less preprocessing.
  - **Recipe 2 (Advanced)** (`3_recipe2_advanced.R`): Incorporates additional transformations, such as non-linear feature engineering and refined categorical encoding.
  
#### Assessment Metric
Model performance will be evaluated using **Root Mean Squared Error (RMSE)** because it emphasizes large errors and aligns with the goal of predicting prices accurately.


## Modeling Progress

#### Baseline Model
```{r}
#| label: tbl-baseline-performance
#| tbl-cap: "Baseline Model Performance"
#| echo: false

library(knitr)
library(here)

# load baseline performance
load(here("results/model_performance_baseline.rda"))

# display results
kable(baseline_performance)

```

The **Baseline Model** predicts the **mean Airbnb price** for all listings, resulting in an **RMSE of 202.74**. This model is a starting point for comparison since it does not use any predictors. A lower RMSE in other models means better accuracy.


#### Linear Model
```{r}
#| label: tbl-lm-performance
#| tbl-cap: "Linear Model Performance"
#| echo: false

library(knitr)
library(here)

# load linear model performance
load(here("results/model_performance_lm.rda"))

# display results
kable(lm_performance)

```
The **Linear Model** improves significantly over the baseline, reducing the **RMSE to 157.82**. This suggests that location, room type, and availability help predict price. However, linear models assume a fixed relationship between factors and price, which may limit accuracy if the patterns are more complex.


#### Elastic Net Model
```{r}
#| label: tbl-en-performance
#| tbl-cap: "Elastic Net Model Performance"
#| echo: false

library(knitr)
library(here)

# load elastic net model performance
load(here("results/model_performance_en.rda"))

# display results
kable(elasticnet_performance)

```
The **Elastic Net Model** combines lasso and ridge regression, this resulted in an **RMSE of 188.67**. This is higher than the linear model but lower than the baseline. Regularization helps prevent overfitting but might remove important features. More tuning or feature adjustments could improve performance.

## Progress Summary & Next Steps

#### Current Status

Since Progress Memo 1, significant progress has been made in data preparation and modeling:

  - **Dataset preprocessing**: Cleaned data, handled missing values, and engineered features using four structured recipes.
  - **Baseline Model**: Established a simple mean-based prediction as a reference, RMSE = 202.74.
  - **Linear Model**: Implemented and evaluated a standard regression model, RMSE = 157.82, showing a strong improvement over the baseline.
  - **Elastic Net Model**: Tuned and fitted an Elastic Net regression model, RMSE = 188.67, balancing variable selection and regularization.
  - **Structured Model Pipeline**: Set up organized scripts for data splitting, feature engineering, tuning, and model fitting. 
  
At this stage, **three models have been fitted and evaluated** which have provided insights into pricing prediction for Airbnb listings. The linear model currently performs the best, while Elastic Net may need further tuning.

```{r}
#| label: tbl-summary-performance
#| tbl-cap: "Model Performance Summary"
#| echo: false

# load packages
library(tidyverse)
library(here)
library(knitr)

# load model performance results
load(here("results/model_performance_baseline.rda"))
load(here("results/model_performance_lm.rda"))
load(here("results/model_performance_en.rda"))

# combine model performances into a summary table
model_performance_summary <- bind_rows(
  baseline_performance,
  lm_performance,
  elasticnet_performance
)

# display model performance table
kable(model_performance_summary)
```


#### Potential Challenges
  - **Handling Outliers**: Extreme Airbnb prices, $10,000 listings, may affect performance. Alternative modeling strategies may help manage extreme listings.
  - **Time Concerns**: Some models like the tree-based methods may take longer to tune.
  

#### Next Steps  

  - **Train Remaining Models**: Fit Lasso, Random Forest, and Boosted Trees using the same process.
  - **Improve Features**: Test if Recipe 2 (Advanced) boosts model performance.
  - **Tune Elastic Net**: Adjust settings to improve accuracy.
  - **Find Key Factors**: Identify which variables impact pricing the most.
  - **Pick the Best Model**: Compare RMSE values to choose the top performer.

#### Final Project Goals

  - Make Final Predictions
  - Interpret Findings
  - Complete Executive Summary

